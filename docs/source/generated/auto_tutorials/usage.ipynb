{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Run pyLossless using an example dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First import we import our packages for this tutorial. \nWe 'll import pylossless as ll for expediency.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tempfile\n\nimport pandas as pd\n\nfrom mne.datasets import sample\nimport mne_bids\n\nimport openneuro\n\nimport pylossless as ll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading the pipeline configuration\nRunning the pipeline always requires 1) a dataset and 2) a configuration\nfile describing the parameters for the preprocessing. A default version of\nthis configuration file can be fetched as a starting point that can be\nadjusted to the specific needs of a given project\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "config = ll.config.Config()\nconfig.load_default()\nconfig.print()\nconfig.save(\"my_project_ll_config.yaml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading an example BIDS compliant dataset\nThe PyLossless pipeline expects the EEG recordings to be stored as BIDS data.\nWe can demonstrate the usage of the pipeline on a BIDS dataset loaded from\nOpenNeuro. First, we need to download the dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Shamelessly copied from https://mne.tools/mne-bids/stable/auto_examples/read_bids_datasets.html\n# pip install openneuro-py\ndataset = 'ds002778'\nsubject = 'pd6'\n\n# Download one subject's data from each dataset\nbids_root = sample.data_path() / dataset\nbids_root.mkdir(exist_ok=True)\n\nopenneuro.download(dataset=dataset, target_dir=bids_root,\n                   include=[f'sub-{subject}'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Running the pipelin on the BIDS compliant dataset\nNow that we have a BIDS dataset saved locally, we can use mne_bids to load\nthis dataset as as mne.io.Raw instance\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datatype = 'eeg'\nsession = 'off'\ntask = 'rest'\nsuffix = 'eeg'\nbids_path = mne_bids.BIDSPath(subject=subject, session=session, task=task,\n                              suffix=suffix, datatype=datatype, root=bids_root)\nraw = mne_bids.read_raw_bids(bids_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great! We have our two ingredients (a dataset and a configuration file),\nand we can now run the pipeline on that dataset (actually, just one recording\nin that case)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline = ll.LosslessPipeline('my_project_ll_config.yaml')\npipeline.run(raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that running the pipeline for a full dataset is not much more\ncomplicated. We only need a list of BIDSPath for all the recordings of that\ndataset. For example, if bids_paths contains such a list, the whole dataset\ncan be processed as follows:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline.run_dataset(bids_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function essentially loads one raw instance after another from the BIDS\nrecordings specified in bids_paths and calls pipeline.run(raw) with these\nraw objects.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Making your own data BIDS compliant\nPyLossless provides some functions to help the user import non-BIDS\nrecordings. Since the code to import datasets recorded in different formats\nand with different properties can vary much from one project to the next, the\nuser must provide a function that can load and return a raw object along with\nthe standard MNE events array and event_id dictionary. For example, in the\ncase of our dataset\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example import function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def egi_import_fct(path_in, stim_channel):\n\n    # read in a file\n    raw = mne.io.read_raw_egi(path_in, preload=True)\n\n    # events and event IDs for events sidecar\n    events = mne.find_events(raw, stim_channel=['STI 014'])\n    event_id = raw.event_id\n\n    # MNE-BIDS doesn't currently support RawMFF objects.\n    with tempfile.TemporaryDirectory() as temp_dir:\n        raw.save(Path(temp_dir) / \"tmp_raw.fif\")\n\n        # preload=True is important since this file is volatile\n        raw = mne.io.read_raw_fif(Path(temp_dir) / 'tmp_raw.fif', preload=True)\n\n    # we only want EEG channels in the channels sidecar\n    raw.pick_types(eeg=True, stim=False)\n    raw.rename_channels({'E129': 'Cz'})  # to make compatible with montage\n\n    return raw, events, event_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, the dataset can be converted to BIDS as follows\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import_args = [{\"stim_channel\": 'STI 014', \"path_in\": './sub-s004-ses_07_task-MMN_20220218_022348.mff'},\n               {\"stim_channel\": 'STI 014', \"path_in\": './sub-s004-ses_07_task-MMN_20220218_022348.mff'}]\n\nbids_path_args = [{'subject': '001', 'run': '01', 'session': '01', \"task\": \"mmn\"},\n                  {'subject': '002', 'run': '01', 'session': '01', \"task\": \"mmn\"}]\n\nbids_paths = ll.bids.convert_dataset_to_bids(egi_import_fct, import_args, bids_path_args, overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that, in this case, we used twice the same input file just to\ndemonstrate how this function can be used for multiple recordings. In\npractice, a user may want to have this information stored in CSV files that\ncan be readily used. For example, if we create such files for the demonstration:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(import_args).to_csv(\"import_args.csv\", index=False)\npd.DataFrame(bids_path_args).to_csv(\"bids_path_args.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, regardless of how such files have been produced (e.g., from Excel),\nthese can be used directly to process the whole dataset:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import_args = list(pd.read_csv(\"import_args.csv\").T.to_dict().values())\nbids_path_args = list(pd.read_csv(\"bids_path_args.csv\").T.to_dict().values())\nbids_paths = ll.bids.convert_dataset_to_bids(egi_import_fct, import_args, bids_path_args, overwrite=True)\npipeline.run_dataset(bids_paths)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}